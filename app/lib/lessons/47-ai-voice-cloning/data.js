export default {
  "id": 47,
  "title": "AI Voice Cloning Scams",
  "emoji": "üéôÔ∏è",
  "description": "The classic family emergency scam, now with real voices.",
  "introduction": "Learn to recognize and protect yourself from AI Voice Cloning Scams.",
  "warning_signs": [],
  "what_to_do": [],
  "how_it_works": "",
  "questions": [
    {
      "type": 1,
      "prompt": "You hear your son's voice on the phone crying. He says he broke his nose.",
      "options": [
        "Panic",
        "Be skeptical. Scammers use 'injuries' to explain why the voice sounds slightly off.",
        "Send money",
        "Run"
      ],
      "correct": 1,
      "explanation": "Claiming a broken nose or bad signal masks the imperfections in the AI voice clone."
    },
    {
      "type": 1,
      "prompt": "How long does a scammer need to clone a voice?",
      "options": [
        "1 hour",
        "3 seconds of clear audio",
        "1 day",
        "1 week"
      ],
      "correct": 1,
      "explanation": "Modern AI needs very little data, often scraped from a TikTok or voicemail greeting."
    },
    {
      "type": 1,
      "prompt": "The 'son' asks for money via Bitcoin ATM.",
      "options": [
        "Send it",
        "Scam. Even if the voice is real, the payment method is the red flag.",
        "Hurry",
        "Help"
      ],
      "correct": 1,
      "explanation": "Always look at the payment method. Kids don't ask for Bitcoin in emergencies."
    },
    {
      "type": 1,
      "prompt": "They call from an unknown number.",
      "options": [
        "Lost phone",
        "Suspicious. Call the known number immediately.",
        "New sim",
        "Answer"
      ],
      "correct": 1,
      "explanation": "Don't accept the 'I lost my phone' excuse without verifying."
    },
    {
      "type": 1,
      "prompt": "You ask a personal question and the line goes silent.",
      "options": [
        "Bad signal",
        "The scammer is typing your question into the AI to generate an answer.",
        "Sad",
        "Crying"
      ],
      "correct": 1,
      "explanation": "Latency (delay) is a sign they are generating audio in real-time."
    },
    {
      "type": 1,
      "prompt": "Can AI mimic accents?",
      "options": [
        "No",
        "Yes, perfectly",
        "Maybe",
        "Only US"
      ],
      "correct": 1,
      "explanation": "AI can replicate regional accents and speech patterns."
    },
    {
      "type": 1,
      "prompt": "Establish a family 'Safe Word'.",
      "options": [
        "Paranoid",
        "Essential security. If they can't say it, hang up.",
        "Silly",
        "Hard"
      ],
      "correct": 1,
      "explanation": "A secret word is the ultimate defense against voice cloning."
    },
    {
      "type": 1,
      "prompt": "They claim to be in a 'holding cell'.",
      "options": [
        "Scary",
        "Standard script to explain why they can't talk long.",
        "True",
        "Help"
      ],
      "correct": 1,
      "explanation": "Limited talk time prevents you from noticing audio glitches."
    },
    {
      "type": 1,
      "prompt": "Does the caller ID prove it's them?",
      "options": [
        "Yes",
        "No, caller ID spoofing + AI voice is a deadly combo.",
        "Always",
        "Maybe"
      ],
      "correct": 1,
      "explanation": "Scammers can fake the number to look like 'Mum' or 'Dad'."
    },
    {
      "type": 1,
      "prompt": "What to do?",
      "options": [
        "Hang up, call original number",
        "Pay",
        "Listen",
        "Record"
      ],
      "correct": 0,
      "explanation": "Break the connection."
    },
    {
      "type": 2,
      "prompt": "You receive a call with screaming audio that sounds exactly like your spouse.",
      "options": [
        "Pay ransom",
        "AI voice clone. Verify their location independently.",
        "Panic",
        "Police"
      ],
      "correct": 1,
      "explanation": "Scammers use AI to generate screams/pleas for help to terrify you."
    },
    {
      "type": 2,
      "prompt": "They demand you stay on the line and do not hang up.",
      "options": [
        "Okay",
        "Control tactic. They don't want you calling the 'victim' to verify safety.",
        "Listen",
        "Obey"
      ],
      "correct": 1,
      "explanation": "Isolation is key. If you hang up and call your spouse, the scam fails."
    },
    {
      "type": 2,
      "prompt": "They know your address and family names.",
      "options": [
        "Real kidnappers",
        "Social engineering from Facebook/Instagram.",
        "Spies",
        "Magic"
      ],
      "correct": 1,
      "explanation": "They harvest this data to make the threat credible."
    },
    {
      "type": 2,
      "prompt": "The ransom amount is relatively low ($1k-$5k).",
      "options": [
        "Cheap life",
        "Designed for fast payment via transfer.",
        "Deal",
        "Lucky"
      ],
      "correct": 1,
      "explanation": "Virtual kidnappers want quick cash, not a police standoff."
    },
    {
      "type": 2,
      "prompt": "You hear police sirens in the background audio.",
      "options": [
        "Real",
        "Sound effects played to increase stress.",
        "Help",
        "Close"
      ],
      "correct": 1,
      "explanation": "They use soundboards to create an atmosphere of chaos."
    },
    {
      "type": 2,
      "prompt": "The 'victim' is actually safe at work.",
      "options": [
        "Relief",
        "Most likely outcome. It's a psychological trick.",
        "Confused",
        "Lucky"
      ],
      "correct": 1,
      "explanation": "Physical kidnapping is rare; virtual kidnapping is common."
    },
    {
      "type": 2,
      "prompt": "How to verify?",
      "options": [
        "Ask scammer",
        "Track their phone location (Find My iPhone) or call their work.",
        "Pay",
        "Wait"
      ],
      "correct": 1,
      "explanation": "Use technology to locate them silently."
    },
    {
      "type": 2,
      "prompt": "They demand payment via gift cards.",
      "options": [
        "Pay",
        "Kidnappers don't take iTunes cards. Scam.",
        "Okay",
        "Fast"
      ],
      "correct": 1,
      "explanation": "Payment method is the giveaway."
    },
    {
      "type": 2,
      "prompt": "Should you challenge them?",
      "options": [
        "Yes, ask the AI a question only the real person knows.",
        "No",
        "Cry",
        "Beg"
      ],
      "correct": 0,
      "explanation": "Ask: 'What did we eat for dinner last night?'"
    },
    {
      "type": 2,
      "prompt": "Preventative measure?",
      "options": [
        "Hide",
        "Set social media to private so they can't find family info.",
        "Run",
        "Delete"
      ],
      "correct": 1,
      "explanation": "Limit their intel."
    },
    {
      "type": 3,
      "prompt": "You get a voicemail from the CEO asking to wire $50k to a vendor.",
      "options": [
        "Do it",
        "Verify. AI clones are used for 'Deepfake Vishing'.",
        "Boss said so",
        "Hurry"
      ],
      "correct": 1,
      "explanation": "Voice phishing (Vishing) targets finance teams."
    },
    {
      "type": 3,
      "prompt": "The request bypasses normal approval channels.",
      "options": [
        "Executive override",
        "Red flag. Verify via internal chat/email.",
        "Okay",
        "Fast"
      ],
      "correct": 1,
      "explanation": "Scammers rely on you being too scared to question the boss."
    },
    {
      "type": 3,
      "prompt": "Where did they get the CEO's voice?",
      "options": [
        "Meeting",
        "YouTube, Webinars, Podcasts, Earnings Calls.",
        "Spy",
        "Phone"
      ],
      "correct": 1,
      "explanation": "Executives have hours of high-quality audio online."
    },
    {
      "type": 3,
      "prompt": "The tone is urgent and authoritative.",
      "options": [
        "Normal boss",
        "Psychological pressure to stop you thinking.",
        "Angry",
        "Rude"
      ],
      "correct": 1,
      "explanation": "Urgency kills scrutiny."
    },
    {
      "type": 3,
      "prompt": "They ask for secrecy due to a 'merger' or 'acquisition'.",
      "options": [
        "Cool",
        "Common script to prevent you asking colleagues.",
        "Secret",
        "Insider"
      ],
      "correct": 1,
      "explanation": "Fake confidentiality ensures you don't double-check."
    },
    {
      "type": 3,
      "prompt": "Live phone call vs Voicemail.",
      "options": [
        "Same",
        "Live is harder for AI (latency), but possible. Voicemail is easier.",
        "Live safer",
        "Voicemail safer"
      ],
      "correct": 1,
      "explanation": "Voicemail is safer for scammers as it needs no interaction."
    },
    {
      "type": 3,
      "prompt": "The bank details are new/overseas.",
      "options": [
        "Global biz",
        "Laundering destination.",
        "New vendor",
        "Okay"
      ],
      "correct": 1,
      "explanation": "Always verify new accounts."
    },
    {
      "type": 3,
      "prompt": "Multi-Factor Verification.",
      "options": [
        "Waste",
        "Call the CEO on their known mobile to confirm.",
        "Hard",
        "Slow"
      ],
      "correct": 1,
      "explanation": "Two channels of communication prevent fraud."
    },
    {
      "type": 3,
      "prompt": "Deepfake audio in Zoom meetings.",
      "options": [
        "Impossible",
        "Possible. Scammers join with camera off and fake audio.",
        "Future",
        "Sci-fi"
      ],
      "correct": 1,
      "explanation": "Audio-only participation is a risk."
    },
    {
      "type": 3,
      "prompt": "Company policy.",
      "options": [
        "Trust voice",
        "Never authorize payments on voice alone.",
        "Fast",
        "Easy"
      ],
      "correct": 1,
      "explanation": "Written approval is mandatory."
    },
    {
      "type": 4,
      "prompt": "Does 'My voice is my password' work against AI?",
      "options": [
        "Yes",
        "No, AI clones can often fool banking voice biometrics.",
        "Always",
        "100%"
      ],
      "correct": 1,
      "explanation": "Researchers have proven AI can bypass these systems."
    },
    {
      "type": 4,
      "prompt": "How do scammers get the sample to hack your bank?",
      "options": [
        "Magic",
        "Spam calls recording you saying 'Yes' or 'My name is...'.",
        "Hacking",
        "Buying"
      ],
      "correct": 1,
      "explanation": "They call you, stay silent, wait for you to speak, and record it."
    },
    {
      "type": 4,
      "prompt": "Should you disable Voice ID?",
      "options": [
        "Maybe",
        "Consider using App/2FA instead if you are a high-value target.",
        "No",
        "Never"
      ],
      "correct": 1,
      "explanation": "It is convenient but has vulnerabilities."
    },
    {
      "type": 4,
      "prompt": "The 'Yes' scam.",
      "options": [
        "Myth",
        "They record you saying 'Yes' to authorize charges.",
        "Real",
        "Scary"
      ],
      "correct": 1,
      "explanation": "Simple affirmations can be spliced into fake authorizations."
    },
    {
      "type": 4,
      "prompt": "Banks detecting AI.",
      "options": [
        "Perfect",
        "An arms race. Detection is good, but AI is getting better.",
        "No",
        "Yes"
      ],
      "correct": 1,
      "explanation": "It is a constant battle between generation and detection."
    },
    {
      "type": 4,
      "prompt": "What adds security to Voice ID?",
      "options": [
        "Loud volume",
        "Being asked random dynamic questions, not just a passphrase.",
        "Whispering",
        "Yelling"
      ],
      "correct": 1,
      "explanation": "Dynamic conversation is harder to clone live."
    },
    {
      "type": 4,
      "prompt": "Protecting your voicemail greeting.",
      "options": [
        "Use name",
        "Use default greeting. Don't record your own name/voice.",
        "Long message",
        "Funny"
      ],
      "correct": 1,
      "explanation": "Your voicemail is a free sample of your voice for scammers."
    },
    {
      "type": 4,
      "prompt": "If your bank calls and asks for your voice phrase.",
      "options": [
        "Say it",
        "Hang up. Banks don't call YOU to check voice ID.",
        "Verify",
        "Trust"
      ],
      "correct": 1,
      "explanation": "They only check voice ID when YOU call THEM."
    },
    {
      "type": 4,
      "prompt": "Synthesized vs Replayed.",
      "options": [
        "Same",
        "Replay attacks play your real voice. Synthesis creates new words.",
        "Different",
        "Audio"
      ],
      "correct": 1,
      "explanation": "AI synthesis is dangerous because it can say anything."
    },
    {
      "type": 4,
      "prompt": "Best defense?",
      "options": [
        "Silence",
        "Monitor accounts + App 2FA",
        "No phone",
        "Cash"
      ],
      "correct": 1,
      "explanation": "Layered security."
    },
    {
      "type": 5,
      "prompt": "Your online date sends voice notes but refuses video calls.",
      "options": [
        "Shy",
        "Using AI text-to-speech to create a fake persona.",
        "Busy",
        "Real"
      ],
      "correct": 1,
      "explanation": "Scammers use AI to generate attractive voices for text interactions."
    },
    {
      "type": 5,
      "prompt": "The voice sounds generic or like a movie trailer.",
      "options": [
        "Cool",
        "Stock AI voice model.",
        "Actor",
        "Rich"
      ],
      "correct": 1,
      "explanation": "If they sound like a GPS navigation system, it's AI."
    },
    {
      "type": 5,
      "prompt": "They can't pronounce local town names correctly.",
      "options": [
        "Foreign",
        "AI limitation with local slang/places.",
        "New",
        "Cute"
      ],
      "correct": 1,
      "explanation": "AI models often fail on Australian place names (e.g., 'Cairns', 'Coogee')."
    },
    {
      "type": 5,
      "prompt": "They send voice messages instead of typing.",
      "options": [
        "Lazy",
        "Building intimacy faster than text.",
        "Personal",
        "Nice"
      ],
      "correct": 1,
      "explanation": "Voice notes create a false sense of closeness."
    },
    {
      "type": 5,
      "prompt": "You ask them to sing or hum.",
      "options": [
        "They do it",
        "They refuse. AI struggles with melody/singing.",
        "Embarrassed",
        "Bad singer"
      ],
      "correct": 1,
      "explanation": "Complex vocal tasks trip up AI."
    },
    {
      "type": 5,
      "prompt": "The background noise cuts out instantly when they stop speaking.",
      "options": [
        "Quiet room",
        "Artificial gating. AI generates silence between words.",
        "Good mic",
        "Studio"
      ],
      "correct": 1,
      "explanation": "Real recordings have consistent room tone."
    },
    {
      "type": 5,
      "prompt": "They claim to be from the UK but sound American.",
      "options": [
        "Traveler",
        "Scammer chose the wrong voice model.",
        "Accent",
        "Mixed"
      ],
      "correct": 1,
      "explanation": "Inconsistencies reveal the lie."
    },
    {
      "type": 5,
      "prompt": "Why use AI voice in romance?",
      "options": [
        "Fun",
        "To mask their real gender/accent/location.",
        "Cool",
        "Tech"
      ],
      "correct": 1,
      "explanation": "A male scammer in Nigeria can sound like a female in Sydney."
    },
    {
      "type": 5,
      "prompt": "Live voice changers.",
      "options": [
        "Toy",
        "Real-time AI can change gender/age on calls.",
        "Game",
        "Fun"
      ],
      "correct": 1,
      "explanation": "Real-time disguises are becoming common."
    },
    {
      "type": 5,
      "prompt": "Video call verification.",
      "options": [
        "Essential",
        "The only way to be sure.",
        "Optional",
        "Later"
      ],
      "correct": 1,
      "explanation": "Don't send money until you see the face move and talk in sync."
    },
    {
      "type": 1,
      "prompt": "You call a 'Support Number' and the agent sounds incredibly realistic but repetitive.",
      "options": [
        "Good training",
        "AI conversational bot designed to keep you on the line.",
        "Human",
        "Script"
      ],
      "correct": 1,
      "explanation": "Scammers use AI agents to scale their operations."
    },
    {
      "type": 1,
      "prompt": "The AI agent asks for your credit card to 'verify ID'.",
      "options": [
        "Give",
        "Scam. AI harvesting data.",
        "Verify",
        "Okay"
      ],
      "correct": 1,
      "explanation": "Automated theft."
    },
    {
      "type": 1,
      "prompt": "Latency (delay) in responses.",
      "options": [
        "Satellite",
        "Processing time for the AI to generate a reply.",
        "Slow",
        "Distance"
      ],
      "correct": 1,
      "explanation": "Unnatural pauses are a clue."
    },
    {
      "type": 1,
      "prompt": "Interrupting the agent.",
      "options": [
        "Rude",
        "Test. AI often keeps talking or resets weirdly if interrupted.",
        "Listen",
        "Wait"
      ],
      "correct": 1,
      "explanation": "Humans react naturally to interruptions; bots glitch."
    },
    {
      "type": 1,
      "prompt": "They misinterpret emotional tone.",
      "options": [
        "Bad service",
        "AI lacks empathy detection.",
        "Rude",
        "Robot"
      ],
      "correct": 1,
      "explanation": "If you are angry and they sound cheerful, it's likely a bot."
    },
    {
      "type": 1,
      "prompt": "Search engines promoting fake numbers.",
      "options": [
        "Safe",
        "Scammers use SEO to rank fake AI helplines.",
        "Google",
        "Bing"
      ],
      "correct": 1,
      "explanation": "Don't trust the first number you see on Google."
    },
    {
      "type": 1,
      "prompt": "The AI transfers you to a 'Senior Manager' (Human Scammer).",
      "options": [
        "Escalation",
        "The 'Closer'. The AI qualifies the victim first.",
        "Help",
        "Good"
      ],
      "correct": 1,
      "explanation": "AI filters out skeptical people; humans close the deal."
    },
    {
      "type": 1,
      "prompt": "24/7 Availability.",
      "options": [
        "Great",
        "Scam centers use AI to run 24/7 without staff.",
        "Service",
        "Good"
      ],
      "correct": 1,
      "explanation": "Scale and availability."
    },
    {
      "type": 1,
      "prompt": "They ask you to download AnyDesk.",
      "options": [
        "Download",
        "Scam. Standard tech support script.",
        "Help",
        "Fix"
      ],
      "correct": 1,
      "explanation": "The goal is remote access."
    },
    {
      "type": 1,
      "prompt": "Verify the number.",
      "options": [
        "How?",
        "Go to the official website/app and find contact info there.",
        "Guess",
        "Trust"
      ],
      "correct": 1,
      "explanation": "Source of truth."
    },
    {
      "type": 2,
      "prompt": "Audio clip of a politician admitting to a crime goes viral.",
      "options": [
        "Share",
        "Check source. Audio deepfakes are used for disinformation.",
        "True",
        "Shock"
      ],
      "correct": 1,
      "explanation": "AI can make politicians say anything."
    },
    {
      "type": 2,
      "prompt": "Robocall from the Prime Minister telling you not to vote.",
      "options": [
        "Obey",
        "Voter suppression scam using AI voice.",
        "Listen",
        "Vote"
      ],
      "correct": 1,
      "explanation": "Happened in the US (Biden fake call). Coming to other elections."
    },
    {
      "type": 2,
      "prompt": "The audio has no video proof.",
      "options": [
        "Suspicious",
        "Audio is easier to fake than video. Be skeptical.",
        "Radio",
        "Secret"
      ],
      "correct": 1,
      "explanation": "Audio-only leaks are high risk for fakes."
    },
    {
      "type": 2,
      "prompt": "Investment advice from a 'Celebrity' voice note.",
      "options": [
        "Invest",
        "Scam. Using authority to sell crypto.",
        "Rich",
        "Tips"
      ],
      "correct": 1,
      "explanation": "Fake audio of Elon Musk/Bezos."
    },
    {
      "type": 2,
      "prompt": "How to verify political audio?",
      "options": [
        "Trust TikTok",
        "Wait for reputable news outlets to verify metadata.",
        "Share",
        "Believe"
      ],
      "correct": 1,
      "explanation": "Journalists have tools to detect edits."
    },
    {
      "type": 2,
      "prompt": "It confirms your bias perfectly.",
      "options": [
        "True",
        "Confirmation bias makes you less critical of fakes.",
        "Good",
        "Right"
      ],
      "correct": 1,
      "explanation": "Scammers target your existing beliefs."
    },
    {
      "type": 2,
      "prompt": "Can audio watermarking help?",
      "options": [
        "Yes",
        "Technology to embed 'fake' tags in AI audio is developing.",
        "No",
        "Maybe"
      ],
      "correct": 1,
      "explanation": "C2PA standards."
    },
    {
      "type": 2,
      "prompt": "The 'Hot Mic' moment.",
      "options": [
        "Leak",
        "Common format for fake audio scandals.",
        "Oops",
        "Real"
      ],
      "correct": 1,
      "explanation": "Staged 'accidental' recordings."
    },
    {
      "type": 2,
      "prompt": "Share responsibility.",
      "options": [
        "Share fast",
        "Don't share unverified sensational audio.",
        "Viral",
        "Post"
      ],
      "correct": 1,
      "explanation": "Stop the spread."
    },
    {
      "type": 2,
      "prompt": "Who creates these?",
      "options": [
        "Pranksters",
        "State actors/Scammers aiming to destabilize.",
        "Kids",
        "TV"
      ],
      "correct": 1,
      "explanation": "Disinformation warfare."
    },
    {
      "type": 3,
      "prompt": "Is your TikTok/Instagram public?",
      "options": [
        "Yes",
        "Your voice is available for cloning.",
        "No",
        "Private"
      ],
      "correct": 1,
      "explanation": "Public videos are training data."
    },
    {
      "type": 3,
      "prompt": "Telephone surveys.",
      "options": [
        "Helpful",
        "Risk. They may be recording your answers to clone you.",
        "Answer",
        "Talk"
      ],
      "correct": 1,
      "explanation": "Don't talk to strangers."
    },
    {
      "type": 3,
      "prompt": "The 'Can you hear me?' scam.",
      "options": [
        "Yes",
        "Don't answer. They record your 'Yes' for fraud.",
        "What?",
        "Hang up"
      ],
      "correct": 1,
      "explanation": "They need affirmative words."
    },
    {
      "type": 3,
      "prompt": "Voice biometrics data breach.",
      "options": [
        "Scary",
        "If a bank/gov database is hacked, your voice print is stolen.",
        "Rare",
        "Fine"
      ],
      "correct": 1,
      "explanation": "Unlike a password, you can't change your voice."
    },
    {
      "type": 3,
      "prompt": "Scraping voicemail.",
      "options": [
        "Possible",
        "Yes, hacking voicemail inboxes to get samples.",
        "No",
        "Hard"
      ],
      "correct": 1,
      "explanation": "Default PINs allow hackers access."
    },
    {
      "type": 3,
      "prompt": "Do you talk loudly in public?",
      "options": [
        "Yes",
        "Someone could record you nearby.",
        "No",
        "Quiet"
      ],
      "correct": 1,
      "explanation": "Physical proximity recording."
    },
    {
      "type": 3,
      "prompt": "Using AI voice changers for fun.",
      "options": [
        "Fun",
        "Uploading your voice to random apps gives them the data.",
        "Game",
        "App"
      ],
      "correct": 1,
      "explanation": "Read the Terms of Service."
    },
    {
      "type": 3,
      "prompt": "Corporate videos.",
      "options": [
        "Work",
        "High quality audio of executives for CEO fraud.",
        "Safe",
        "Job"
      ],
      "correct": 1,
      "explanation": "Executives are high risk."
    },
    {
      "type": 3,
      "prompt": "How to protect your voice?",
      "options": [
        "Silence",
        "Limit public posts, use non-biometric security.",
        "Whisper",
        "Mask"
      ],
      "correct": 1,
      "explanation": "Reduce exposure."
    },
    {
      "type": 3,
      "prompt": "Opt-out.",
      "options": [
        "Yes",
        "Remove your voice from AI training datasets if possible.",
        "No",
        "Hard"
      ],
      "correct": 1,
      "explanation": "Privacy rights."
    },
    {
      "type": 4,
      "prompt": "Is voice cloning illegal?",
      "options": [
        "Yes",
        "Not the tech itself, but using it for fraud is.",
        "No",
        "Maybe"
      ],
      "correct": 1,
      "explanation": "Tools are legal; fraud is not."
    },
    {
      "type": 4,
      "prompt": "Can you copyright your voice?",
      "options": [
        "Yes",
        "Complex legal area. 'Right of Publicity' applies in some places.",
        "No",
        "Maybe"
      ],
      "correct": 1,
      "explanation": "Laws are lagging behind tech."
    },
    {
      "type": 4,
      "prompt": "Deepfake disclosure laws.",
      "options": [
        "Exist",
        "Some regions require labeling AI content.",
        "None",
        "Future"
      ],
      "correct": 1,
      "explanation": "Regulation is increasing."
    },
    {
      "type": 4,
      "prompt": "Can audio be used in court?",
      "options": [
        "Yes",
        "Increasingly challenged due to deepfake potential.",
        "No",
        "Always"
      ],
      "correct": 1,
      "explanation": "The 'Liar's Dividend' - people claiming real evidence is fake."
    },
    {
      "type": 4,
      "prompt": "Consent.",
      "options": [
        "Required",
        "Ethical AI requires consent to clone.",
        "Optional",
        "No"
      ],
      "correct": 1,
      "explanation": "Scammers ignore consent."
    },
    {
      "type": 4,
      "prompt": "Platform responsibility.",
      "options": [
        "None",
        "Platforms are pressured to detect/ban deepfakes.",
        "Total",
        "Users"
      ],
      "correct": 1,
      "explanation": "Social media must police this."
    },
    {
      "type": 4,
      "prompt": "Victim support.",
      "options": [
        "IDCARE",
        "Police",
        "eSafety",
        "All of above"
      ],
      "correct": 3,
      "explanation": "Help is available."
    },
    {
      "type": 4,
      "prompt": "Identity theft classification.",
      "options": [
        "Yes",
        "Voice cloning is a form of biometric ID theft.",
        "No",
        "Maybe"
      ],
      "correct": 1,
      "explanation": "It steals a biological trait."
    },
    {
      "type": 4,
      "prompt": "Insurance coverage.",
      "options": [
        "Yes",
        "Cyber insurance may cover social engineering losses.",
        "No",
        "Rare"
      ],
      "correct": 1,
      "explanation": "Check your policy."
    },
    {
      "type": 4,
      "prompt": "Future outlook.",
      "options": [
        "Better",
        "Will get harder to detect before it gets easier.",
        "Gone",
        "Safe"
      ],
      "correct": 1,
      "explanation": "The tech is improving fast."
    },
    {
      "type": 5,
      "prompt": "The #1 Defense against family scams.",
      "options": [
        "Gun",
        "Safe Word / Code Word",
        "Phone",
        "Police"
      ],
      "correct": 1,
      "explanation": "Simple and effective."
    },
    {
      "type": 5,
      "prompt": "Call back protocol.",
      "options": [
        "Always",
        "Hang up and call their known number.",
        "Never",
        "Text"
      ],
      "correct": 1,
      "explanation": "Verify the channel."
    },
    {
      "type": 5,
      "prompt": "Listen for...",
      "options": [
        "Breath",
        "Robotic monotone, clipping, strange pauses.",
        "Loudness",
        "Accent"
      ],
      "correct": 1,
      "explanation": "Audio artifacts."
    },
    {
      "type": 5,
      "prompt": "Question harder.",
      "options": [
        "Yes",
        "Ask personal info only they know.",
        "No",
        "Rude"
      ],
      "correct": 1,
      "explanation": "Test the AI's knowledge base."
    },
    {
      "type": 5,
      "prompt": "Payment red flags.",
      "options": [
        "Card",
        "Crypto, Gift Cards, Urgent Wires.",
        "Cash",
        "Cheque"
      ],
      "correct": 1,
      "explanation": "Follow the money."
    },
    {
      "type": 5,
      "prompt": "Privacy settings.",
      "options": [
        "Open",
        "Locked down to friends only.",
        "Public",
        "Shared"
      ],
      "correct": 1,
      "explanation": "Starve the AI of data."
    },
    {
      "type": 5,
      "prompt": "Skepticism.",
      "options": [
        "Healthy",
        "Believe everything",
        "Cynical",
        "Trust"
      ],
      "correct": 0,
      "explanation": "Trust but verify."
    },
    {
      "type": 5,
      "prompt": "Report suspicious calls.",
      "options": [
        "Scamwatch",
        "Ignore",
        "Delete",
        "Mum"
      ],
      "correct": 0,
      "explanation": "Data helps fight crime."
    },
    {
      "type": 5,
      "prompt": "Educate family.",
      "options": [
        "Yes",
        "Talk about AI scams at dinner.",
        "No",
        "Boring"
      ],
      "correct": 1,
      "explanation": "Herd immunity."
    },
    {
      "type": 5,
      "prompt": "Don't trust Caller ID.",
      "options": [
        "True",
        "False",
        "Sometimes",
        "Maybe"
      ],
      "correct": 0,
      "explanation": "It is easily faked."
    }
  ]
};